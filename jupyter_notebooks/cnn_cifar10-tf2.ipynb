{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning with Tensorflow\n",
    "# get data here http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "# run python tensorflow 1.x code\n",
    "# https://github.com/BinRoot/TensorFlow-Book.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, MaxPool2D\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, layers\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    this_dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return this_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "def clean(data):\n",
    "    imgs = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    grayscale_imgs = imgs.mean(1)\n",
    "    cropped_imgs = grayscale_imgs[:, 4:28, 4:28]\n",
    "    img_data = cropped_imgs.reshape(data.shape[0], -1)\n",
    "    img_size = np.shape(img_data)[1]\n",
    "    means = np.mean(img_data, axis=1)\n",
    "    meansT = means.reshape(len(means), 1)\n",
    "    stds = np.std(img_data, axis=1)\n",
    "    stdsT = stds.reshape(len(stds), 1)\n",
    "    adj_stds = np.maximum(stdsT, 1.0 / np.sqrt(img_size))\n",
    "    normalized = (img_data - meansT) / adj_stds\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(directory):\n",
    "    names = unpickle('{}/batches.meta'.format(directory))['label_names']\n",
    "    print('names', names)\n",
    "    data, labels = [], []\n",
    "    for i in range(1, 6):\n",
    "        filename = '{}/data_batch_{}'.format(directory, i)\n",
    "        batch_data = unpickle(filename)\n",
    "        if len(data) > 0: \n",
    "            data = np.vstack((data, batch_data['data']))\n",
    "            labels = np.hstack((labels, batch_data['labels'])\n",
    "                              )        \n",
    "        else:\n",
    "            data = batch_data['data']\n",
    "            labels = batch_data['labels']\n",
    "    print(np.shape(data), np.shape(labels))\n",
    "    data = clean(data) \n",
    "    data = data.astype(np.float32)\n",
    "    return names, data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "(50000, 3072) (50000,)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "names, data, labels = \\\n",
    "    read_data(r'D:\\Documents\\1_Projects\\CRSIP_ML\\data\\cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6937296 , -0.71540314, -0.686505  , ..., -0.08686984,\n",
       "        -0.29638094, -0.18801312],\n",
       "       [ 1.3697398 ,  1.2528099 ,  0.72940975, ..., -0.68488437,\n",
       "        -1.1860123 , -1.7038443 ],\n",
       "       [ 1.7809031 ,  1.7809031 ,  1.7809031 , ..., -0.59378237,\n",
       "        -0.58099234, -0.59378237],\n",
       "       ...,\n",
       "       [ 1.12856   ,  1.1333368 ,  1.1715513 , ..., -0.50034004,\n",
       "        -0.6388682 , -0.8012805 ],\n",
       "       [ 1.3223659 ,  1.3432754 ,  1.378125  , ..., -0.8173882 ,\n",
       "        -1.2704306 , -3.382305  ],\n",
       "       [ 0.09468836,  0.33273417,  0.56377864, ...,  0.01767354,\n",
       "        -0.19236688, -0.03133589]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 24, 24, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "# data_reshaped = tf.reshape(data, shape=[-1, 24, 24, 1])\n",
    "data_reshaped = data.reshape(data.shape[0], 24, 24, 1)\n",
    "data_reshaped.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 24, 24, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape  = data_reshaped.shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, 3, activation='relu', input_shape=(24, 24, 1)))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "model.add(layers.MaxPool2D(padding='same'))\n",
    "model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPool2D(padding='same'))\n",
    "model.add(layers.Conv2D(128, 1, activation='relu'))\n",
    "model.add(layers.MaxPool2D(padding='same'))\n",
    "model.add(layers.Conv2D(256, 1, activation='relu'))\n",
    "\n",
    "#model.add(layers.MaxPool2D())\n",
    "#model.add(layers.Flatten())  # This layer is not compatible with ARM-NN\n",
    "#model.add(layers.Reshape([256])) # still implements as strided slice, not compatible\n",
    "#model.add(layers.Lambda(lambda x: K.reshape(x, [-1, 256])))  # reshape from/to 4D tensor not supported\n",
    "#model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 22, 22, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 9, 9, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 128)         8320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 1, 256)         33024     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 133,002\n",
      "Trainable params: 133,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', metrics=['accuracy'], loss='sparse_categorical_crossentropy')\n",
    "model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cat = to_categorical(labels)\n",
    "labels_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.8064 - accuracy: 0.3352\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.4469 - accuracy: 0.4881\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2917 - accuracy: 0.5485\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.1795 - accuracy: 0.5896\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.0981 - accuracy: 0.6197\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.0393 - accuracy: 0.6390\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9884 - accuracy: 0.6578\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.9499 - accuracy: 0.6723\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.9065 - accuracy: 0.6865\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.8772 - accuracy: 0.6944\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.8446 - accuracy: 0.7089\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.8182 - accuracy: 0.7145\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.7856 - accuracy: 0.7264\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.7653 - accuracy: 0.7323\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.7411 - accuracy: 0.7423\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.7175 - accuracy: 0.7483\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.6974 - accuracy: 0.7547\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6767 - accuracy: 0.7613\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.6574 - accuracy: 0.7689\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6391 - accuracy: 0.7735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b6cd560a48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_reshaped, labels_cat, epochs=20, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
